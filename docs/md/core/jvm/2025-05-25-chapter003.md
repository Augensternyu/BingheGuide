---
layout: post
category: binghe-code-jvm
title: 第03章：GC暂停时长由30秒下降到190毫秒的优化案例
tagline: by 冰河
tag: [jvm,binghe-code-jvm]
excerpt: 第03章：GC暂停时长由30秒下降到190毫秒的优化案例
---

# 经过这么优化后，生产环境JVM GC一次暂停时长由30秒下降到190毫秒！！

**大家好，我是冰河~~**

在高并发下，Java程序的GC问题属于很典型的一类问题，带来的影响往往会被进一步放大。不管是「GC频率过快」还是「GC耗时太长」，由于GC期间都存在Stop The World问题，因此很容易导致服务超时，引发性能问题。

事情最初是线上某应用垃圾收集出现Full GC异常的现象，应用中个别实例Full GC时间特别长，持续时间约为15~30秒，平均每2周左右触发一次；

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-010.png?raw=true" width="80%">
    <br/>
</div>

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-011.png?raw=true" width="80%">
    <br/>
</div>

JVM参数配置：

> -Xms2048M –Xmx2048M –Xmn1024M –XX:MaxPermSize=512M

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-012.png?raw=true" width="80%">
    <br/>
</div>


## 排查过程

### 分析 GC 日志

GC 日志它记录了每一次的 GC 的执行时间和执行结果，通过分析 GC 日志可以调优堆设置和 GC 设置，或者改进应用程序的对象分配模式。

这里Full GC的reason是Ergonomics，是因为开启了UseAdaptiveSizePolicy，jvm自己进行自适应调整引发的Full GC。

这份日志主要体现GC前后的变化，目前为止看不出个所以然来。

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-013.png?raw=true" width="80%">
    <br/>
</div>

开启GC日志，需要添加如下 JVM 启动参数：

> -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/export/log/risk_pillar/gc.log

常见的 Young GC、Full GC 日志含义如下：

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-014.png?raw=true" width="80%">
    <br/>
</div>

### 进一步查看服务器性能指标

获取到了GC耗时的时间后，通过监控平台获取到各个监控项，开始排查这个时点有异常的指标，最终分析发现，在5.06分左右（GC的时点），CPU占用显著提升，而SWAP出现了释放资源、memory资源增长出现拐点的情况（详见下图红色框，橙色框中的变化是因修改配置导致，后面会介绍，暂且可忽略）

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-015.png?raw=true" width="80%">
    <br/>
</div>

JVM用到了swap？

是因为GC导致的CPU突然飙升，并且释放了swap交换区这部分内存到memory？

为了验证JVM是否用到swap，我们通过检查proc下的进程内存资源占用情况

```bash
for i in (cd/proc;ls∣grep"[0−9]"∣awk′0 >100');
do awk '/Swap:/{a=a+2}END{print '"i"',a/1024"M"}' /proc/$i/smaps 2>/dev/null;
done | sort -k2nr | head -10 

# head -10 表示 取出 前10个内存占用高的进程 
# 取出的第一列为进程的id 第二列进程占用swap大小
```

看到确实有用到305MB的swap

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-016.png?raw=true" width="80%">
    <br/>
</div>

这里简单介绍下什么是swap?

swap指的是一个交换分区或文件，主要是在内存使用存在压力时，触发内存回收，这时可能会将部分内存的数据交换到swap空间，以便让系统不会因为内存不够用而导致oom或者更致命的情况出现。

当某进程向OS请求内存发现不足时，OS会把内存中暂时不用的数据交换出去，放在swap分区中，这个过程称为swap out。

当某进程又需要这些数据且OS发现还有空闲物理内存时，又会把swap分区中的数据交换回物理内存中，这个过程称为swap in。

为了验证GC耗时与swap操作有必然关系，我抽查了十几台机器，重点关注耗时长的GC日志，通过时间点确认到GC耗时的时间点与swap操作的时间点确实是一致的。

进一步查看虚拟机各实例 swappiness 参数，一个普遍现象是，凡是发生较长Full GC的实例都配置了参数 vm.swappiness = 30（值越大表示越倾向于使用swap）；而GC时间相对正常的实例配置参数 vm.swappiness = 0（最大限度地降低使用swap）。

swappiness 可以设置为 0 到 100 之间的值，它是Linux的一个内核参数，控制系统在进 行swap时，内存使用的相对权重。

- swappiness=0: 表示最大限度使用物理内存，然后才是 swap空间
- swappiness=100: 表示积极的使用swap分区，并且把内存上的数据及时的交换到swap空间里面

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-017.png?raw=true" width="80%">
    <br/>
</div>


<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-018.png?raw=true" width="80%">
    <br/>
</div>

对应的物理内存使用率和swap使用情况如下

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-019.png?raw=true" width="80%">
    <br/>
</div>

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-020.png?raw=true" width="80%">
    <br/>
</div>

至此，矛头似乎都指向了swap。

## 问题分析

当内存使用率达到水位线(vm.swappiness)时，linux会把一部分暂时不使用的内存数据放到磁盘swap去，以便腾出更多可用内存空间；

当需要使用位于swap区的数据时，再将其换回内存中，当JVM进行GC时，需要对相应堆分区的已用内存进行遍历；

假如GC的时候，有堆的一部分内容被交换到swap空间中，遍历到这部分的时候就需要将其交换回内存，由于需要访问磁盘，所以相比物理内存，它的速度肯定慢的令人发指，GC停顿的时间一定会非常非常恐怖；

进而导致Linux对swap分区的回收滞后（内存到磁盘换入换出操作十分占用CPU与系统IO），在高并发/QPS服务中，这种滞后带来的结果是致命的(STW)。

## 问题解决

至此，答案似乎很清晰，我们只需尝试把swap关闭或释放掉，看看能否解决问题？

**如何释放swap?**

设置vm.swappiness=0（重启应用释放swap后生效），表示尽可能不使用交换内存

方案 a：临时设置方案，重启后不生效

1. 设置vm.swappiness为0，sysctl vm.swappiness=0
2. 查看swappiness值，cat /proc/sys/vm/swappiness

方案b：永久设置方案，重启后仍然生效

1. vi /etc/sysctl.conf
2. 关闭交换分区swapoff –a(前提：首先要保证内存剩余要大于等于swap使用量，否则会报Cannot allocate memory！swap分区一旦释放，所有存放在swap分区的文件都会转存到物理内存上，可能会引发系统IO或者其他问题。)

查看当前swap分区挂载在哪：

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-021.png?raw=true" width="80%">
    <br/>
</div>

关停分区：

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-022.png?raw=true" width="80%">
    <br/>
</div>

关闭swap交换区后的内存变化见下图橙色框，此时swap分区的文件都转存到了物理内存上

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-023.png?raw=true" width="80%">
    <br/>
</div>


关闭Swap交换区后，于2.23再次发生Full GC，耗时190ms，问题得到解决。

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-024.png?raw=true" width="80%">
    <br/>
</div>

## 疑惑

1. 是不是只要开启了swap交换区的JVM，在GC的时候都会耗时较长呢？
2. 既然JVM对swap如此不待见，为何JVM不明令禁止使用呢？
3. swap工作机制是怎样的？这台物理内存为8g的server，使用了交换区内存（swap），说明物理内存不够使用了，但是通过free命令查看内存使用情况，实际物理内存似乎并没有占用那么多，反而Swap已占近1G？

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-025.png?raw=true" width="80%">
    <br/>
</div>

free：除了buff/cache剩余了多少内存

shared：共享内存

buff/cache：缓冲、缓存区内存数（使用过高通常是程序频繁存取文件）

available：真实剩余的可用内存数

## 进一步思考

大家可以想想，关闭交换磁盘缓存意味着什么？

其实大可不必如此激进，要知道这个世界永远不是非0即1的，大家都会或多或少选择走在中间，不过有些偏向0，有些偏向1而已。

很显然，在swap这个问题上，JVM可以选择偏向尽量少用，从而降低swap影响，要降低swap影响有必要弄清楚Linux内存回收是怎么工作的，这样才能不遗漏任何可能的疑点。

**先来看看swap是如何触发的？**

Linux会在两种场景下触发内存回收，一种是在内存分配时发现没有足够空闲内存时会立刻触发内存回收；另一种是开启了一个守护进程（kswapd进程）周期性对系统内存进行检查，在可用内存降低到特定阈值之后主动触发内存回收。

通过如下图示可以很容易理解，详细信息参见：

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-026.png?raw=true" width="80%">
    <br/>
</div>

是不是只要开启了swap交换区的JVM，在GC的时候都会耗时较长？

笔者去查了一下另外的一个应用，相关指标信息请见下图。

实名服务的QPS是非常高的，同样能看到应用了swap，GC平均耗时 576ms，这是为什么呢？

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-027.png?raw=true" width="80%">
    <br/>
</div>

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-028.png?raw=true" width="80%">
    <br/>
</div>


通过把时间范围聚焦到发生GC的某一时间段，从监控指标图可以看到swapUsed没有任何变化，也就是说没有swap活动，进而没有影响到垃级回收的总耗时。

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-029.png?raw=true" width="80%">
    <br/>
</div>

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-030.png?raw=true" width="80%">
    <br/>
</div>

通过如下命令列举出各进程swap空间占用情况，很清楚的看到实名这个服务swap空间占用的较少（仅54.2MB）

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-031.png?raw=true" width="80%">
    <br/>
</div>

另一个显著的现象是实名服务Full GC间隔较短（几个小时一次），而我的服务平均间隔2周一次Full GC

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-032.png?raw=true" width="80%">
    <br/>
</div>

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-033.png?raw=true" width="80%">
    <br/>
</div>

基于以上推测

1. 实名服务由于 GC 间隔较短，内存中的东西根本没有机会置换到swap中就被回收了，GC的时候不需要将swap分区中的数据交换回物理内存中，完全基于内存计算，所以要快很多
2. 将哪些内存数据置换进swap交换区的筛选策略应该是类似于LRU算法（最近最少使用原则）

为了证实上述猜测，我们只需跟踪swap变更日志，监控数据变化即可得到答案，这里采用一段shell 脚本实现

```bash
#!/bin/bash 
echo -e `date +%y%m%d%H%M%S` 
echo -e "PID\t\tSwap\t\tProc_Name" 

#拿出/proc目录下所有以数字为名的目录（进程名是数字才是进程，其他如sys,net等存放的是其他信息） 
for pid in `ls -l /proc | grep ^d | awk '{ print $9 }'| grep -v [^0-9]` 
do 
    if [ $pid -eq 1 ];then continue;fi 
    grep -q "Swap" /proc/$pid/smaps 2>/dev/null 
    if [ $? -eq 0 ];then 
        swap=$(gawk '/Swap/{ sum+=$2;} END{ print sum }' /proc/$pid/smaps) #统计占用的swap分区的 大小 单位是KB 
        proc_name=$(ps aux | grep -w "$pid" | awk '!/grep/{ for(i=11;i<=NF;i++){ printf("%s ",$i); }}') #取出进程的名字 
        if [ $swap -gt 0 ];then #判断是否占用swap 只有占用才会输出 
            echo -e "${pid}\t${swap}\t${proc_name:0:100}" 
    fi 
   fi
done | sort -k2nr | head -10 | gawk -F'\t' '{ #排序取前 10 
    pid[NR]=$1; 
    size[NR]=$2; 
    name[NR]=$3; 
} 
END{ 
    for(id=1;id<=length(pid);id++) 
    { 
    if(size[id]<1024) 
        printf("%-10s\t%15sKB\t%s\n",pid[id],size[id],name[id]); 
    else if(size[id]<1048576) 
        printf("%-10s\t%15.2fMB\t%s\n",pid[id],size[id]/1024,name[id]);
    else 
    printf("%-10s\t%15.2fGB\t%s\n",pid[id],size[id]/1048576,name[id]); 
    } 
}
```

由于上面图中 2022.3.2 19:57:00 至 2022.3.2 19:58:00 发生了一次Full GC，我们重点关注下这一分钟内swap交换区的变化即可，我这里每10s做一次信息采集，可以看到在GC时点前后，swap确实没有变化

<div align="center">
    <img src="https://binghe.gitcode.host/assets/images/core/jvm/2025-05-25-034.png?raw=true" width="80%">
    <br/>
</div>

通过上述分析，回归本文核心问题上，现在看来我的处理方式过于激进了，其实也可以不用关闭swap，通过适当降低堆大小，也是能够解决问题的。

这也侧面的说明，部署Java服务的Linux系统，在内存分配上并不是无脑大而全，需要综合考虑不同场景下JVM对Java永久代 、Java堆(新生代和老年代)、线程栈、Java NIO所使用内存的需求。

## 总结

综上，我们得出结论，swap和GC同一时候发生会导致GC时间非常长，JVM严重卡顿，极端的情况下会导致服务崩溃。

主要原因是：JVM进行GC时，需要对对应堆分区的已用内存进行遍历，假如GC的时候，有堆的一部分内容被交换到swap中，遍历到这部分的时候就须要将其交换回内存；更极端情况同一时刻因为内存空间不足，就需要把内存中堆的另外一部分换到SWAP中去，于是在遍历堆分区的过程中，会把整个堆分区轮流往SWAP写一遍，导致GC时间超长。线上应该限制swap区的大小，如果swap占用比例较高应该进行排查和解决，适当的时候可以通过降低堆大小，或者添加物理内存。

因此，部署Java服务的Linux系统，在内存分配上要慎重。

## 写在最后

在冰河的知识星球有大量从零开始带你手写的企业级生产项目，像DeepSeek大模型、手写高性能熔断组件、手写通用指标上报组件、手写高性能数据库路由组件、分布式IM即时通讯系统、Sekill分布式秒杀系统、手写RPC、简易商城系统等等，这些项目的需求、方案、架构、落地等均来自互联网真实业务场景，让你真正学到互联网大厂的业务与技术落地方案，并将其有效转化为自己的知识储备。

**值得一提的是：冰河自研的Polaris高性能网关比某些开源网关项目性能更高，并且冰河也正在为企业级高性能RPC框架录制视频，全程带你分析原理和手撸代码。** 你还在等啥？不少小伙伴经过星球硬核技术和项目的历练，早已成功跳槽加薪，实现薪资翻倍，而你，还在原地踏步，抱怨大环境不好。抛弃焦虑和抱怨，我们一起塌下心来沉淀硬核技术和项目，让自己的薪资更上一层楼。

<div align="center">
    <img src="https://binghe.gitcode.host/images/personal/xingqiu_149.png?raw=true" width="80%">
    <br/>
</div>

目前，领券加入星球就可以跟冰河一起学习《DeepSeek大模型》、《手写高性能通用熔断组件项目》、《手写高性能通用监控指标上报组件》、《手写高性能数据库路由组件项目》、《手写简易商城脚手架项目》、《手写高性能RPC项目》和《Spring6核心技术与源码解析》、《实战高并发设计模式》、《分布式Seckill秒杀系统》、《分布式IM即时通讯系统》和《手写高性能Polaris网关》，从零开始介绍原理、设计架构、手撸代码。

**花很少的钱就能学这么多硬核技术、中间件项目和大厂秒杀系统与分布式IM即时通讯系统，比其他培训机构不知便宜多少倍，硬核多少倍，如果是我，我会买他个十年！**

加入要趁早，后续还会随着项目和加入的人数涨价，而且只会涨，不会降，先加入的小伙伴就是赚到。

另外，还有一个限时福利，邀请一个小伙伴加入，冰河就会给一笔 **分享有奖** ，有些小伙伴都邀请了50+人，早就回本了！

## 其他方式加入星球

- **链接** ：打开链接 http://m6z.cn/6aeFbs 加入星球。
- **回复** ：在公众号 **冰河技术** 回复 **星球** 领取优惠券加入星球。

**特别提醒：** 苹果用户进圈或续费，请加微信 **hacker_binghe** 扫二维码，或者去公众号 **冰河技术** 回复 **星球** 扫二维码加入星球。

## 联系冰河

### 加群交流

本群的宗旨是给大家提供一个良好的技术学习交流平台，所以杜绝一切广告！由于微信群人满 100 之后无法加入，请扫描下方二维码先添加作者 “冰河” 微信(hacker_binghe)，备注：`星球编号`。



<div align="center">
    <img src="https://binghe.gitcode.host/images/personal/hacker_binghe.jpg?raw=true" width="180px">
    <div style="font-size: 18px;">冰河微信</div>
    <br/>
</div>



### 公众号

分享各种编程语言、开发技术、分布式与微服务架构、分布式数据库、分布式事务、云原生、大数据与云计算技术和渗透技术。另外，还会分享各种面试题和面试技巧。内容在 **冰河技术** 微信公众号首发，强烈建议大家关注。

<div align="center">
    <img src="https://binghe.gitcode.host/images/personal/ice_wechat.jpg?raw=true" width="180px">
    <div style="font-size: 18px;">公众号：冰河技术</div>
    <br/>
</div>


### 视频号

定期分享各种编程语言、开发技术、分布式与微服务架构、分布式数据库、分布式事务、云原生、大数据与云计算技术和渗透技术。另外，还会分享各种面试题和面试技巧。

<div align="center">
    <img src="https://binghe.gitcode.host/images/personal/ice_video.png?raw=true" width="180px">
    <div style="font-size: 18px;">视频号：冰河技术</div>
    <br/>
</div>



### 星球

加入星球 **[冰河技术](http://m6z.cn/6aeFbs)**，可以获得本站点所有学习内容的指导与帮助。如果你遇到不能独立解决的问题，也可以添加冰河的微信：**hacker_binghe**， 我们一起沟通交流。另外，在星球中不只能学到实用的硬核技术，还能学习**实战项目**！

关注 [冰河技术](https://img-blog.csdnimg.cn/20210426115714643.jpg?raw=true)公众号，回复 `星球` 可以获取入场优惠券。

<div align="center">
    <img src="https://binghe.gitcode.host/images/personal/xingqiu.png?raw=true" width="180px">
    <div style="font-size: 18px;">知识星球：冰河技术</div>
    <br/>
</div>

**好了，今天就到这儿吧，我是冰河，我们下期见~~**